---
title: "Project 2 - Car Accident Fatalities"
author: "John, Daniel, Jing, Michael"
date: "11/26/2020"
output: html_document
---

#0. Process

Our process included:

1) Data Import & Cleaning
2) Data Exploration
3) Model Exploration (Full Data Set)
4) Model Selection, Formalization, and Validation (Test & Train Data Set)
5) Highlighting Unique Observations

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(faraway) #used for VIF
library(multcomp)
library(ROCR) #Used for ROC/AUC
library(car) #used for GVIF (to address categorical variables) https://cran.r-project.org/web/packages/car/car.pdf
library(leaps) #For All Regression
library(caret)  #Used for cross validation
library(boot)  #Used for cross validation
library(jtools) #Model Comparison Table
library(tidyverse)
```

# 1. Data Import &Cleaning

### Import Data & Clean

- Load Data
- Drop unwanted columns
- Remove rows with "N/A" (only one exists after unwanted columns removed)


Unwanted Columns:

- X: just a number with no corresponding contextual information
- caseid: just an identifier, not contextually relevant
- weight: used in weighting of observations, not used in our model selection process
- injury severity: will assume that this is not known when presence of fatality is unknown

```{r}

# read csv file
nass <- read.csv("nassCDS.csv", header = T)
lengths(nass)

# drop column, X, caseid, weight, injSeverity
nass=subset(nass, select = -c(X,caseid, weight, injSeverity))
lengths(nass)

# check for rows containing NA
which(is.na(nass), arr.ind=TRUE)

# remove rows containing NA
nass <- nass[complete.cases(nass), ]
lengths(nass)

```

### Convert categorical variables to factors

- Ensure categorical variables are factored
- Change "Dead" from ('alive', 'dead') to (0, 1)

```{r}
#convert categorical to factor
nass$dead<-factor(nass$dead) 
nass$dvcat<-factor(nass$dvcat)
nass$airbag<-factor(nass$airbag)
nass$seatbelt<-factor(nass$seatbelt)
nass$sex<-factor(nass$sex)
nass$abcat<-factor(nass$abcat)
nass$occRole<-factor(nass$occRole)
nass$deploy<-factor(nass$deploy)
nass$abcat<-factor(nass$abcat)

nass$dead_num <- nass$dead
levels(nass$dead_num) <- c(0,1)

#remove column of dead
nass=subset(nass, select = -c(dead))
head(nass, 5)
```



# 2. Exploratory Data Analysis

### Exploratory Data Analysis - Understanding Data & Predictors

Deaths vs. Predictors
```{r}
#Explore predictors we think will be significant
round(prop.table(table(nass$dead_num, nass$dvcat)),3) #proportion table of deaths versus estimated speed of crash
round(prop.table(table(nass$dead_num, nass$seatbelt)),3) #proportion table of deaths versus buckled
round(prop.table(table(nass$dead_num, nass$airbag)),3) #proportion table of deaths versus airbag availability
round(prop.table(table(nass$dead_num, nass$frontal)),3) #proportion table of deaths versus buckled
round(prop.table(table(nass$dead_num, nass$abcat)),3) #proportion table of deaths versus buckled

boxplot(ageOFocc ~ dead_num, data = nass) #boxplot of age of occupant versus death

```

### Exploratory Data Analysis - Influential Data Points


Each Column Individually(only the columns in the final model)
```{r}
nass2<-tibble(New_dvcat, seatbelt, frontal, sex, ageOFocc,abcat, occRole)
print("EACH COLUMN INDIVIDUALLY")
sapply(nass, table)
```

Columns Against Each Other

```{r}
print("New_dvcat")
#mapply(table, nass[,-13], nass[13], USE.NAMES = TRUE, SIMPLIFY = FALSE) #New_dvcat
mapply(table, nass2[,-1], nass2[1], USE.NAMES = TRUE, SIMPLIFY = FALSE) 
```

```{r}
print("Seatbelt")
#mapply(table, nass[,-3], nass[3], USE.NAMES = TRUE, SIMPLIFY = FALSE) #seatbelt
mapply(table, nass2[,-2], nass2[2], USE.NAMES = TRUE, SIMPLIFY = FALSE) 
```

```{r}
print("Frontal")
#mapply(table, nass[,-4], nass[4], USE.NAMES = TRUE, SIMPLIFY = FALSE) #frontal
mapply(table, nass2[,-3], nass2[3], USE.NAMES = TRUE, SIMPLIFY = FALSE) 
```

```{r}
print("sex")
#mapply(table, nass[,-5], nass[5], USE.NAMES = TRUE, SIMPLIFY = FALSE) #sex
mapply(table, nass2[,-4], nass2[4], USE.NAMES = TRUE, SIMPLIFY = FALSE) 
```

```{r}
print("ageOFocc")
#mapply(table, nass[,-6], nass[6], USE.NAMES = TRUE, SIMPLIFY = FALSE) #ageOFocc
mapply(table, nass2[,-5], nass2[5], USE.NAMES = TRUE, SIMPLIFY = FALSE) 
```

```{r}
print("abcat")
#mapply(table, nass[,-9], nass[9], USE.NAMES = TRUE, SIMPLIFY = FALSE) #abcat
mapply(table, nass2[,-6], nass2[6], USE.NAMES = TRUE, SIMPLIFY = FALSE) 
```

```{r}
print("occRole")
#mapply(table, nass[,-10], nass[10], USE.NAMES = TRUE, SIMPLIFY = FALSE) #occRole
mapply(table, nass2[,-7], nass2[7], USE.NAMES = TRUE, SIMPLIFY = FALSE) 
```



Note: As outlined subsequently, traditional measures of influence and leverage are difficult to apply to our data set given the number of categorical variables. We look for potential influential data points by seeking to identify combinations of classes with few observations.



# 3. Model Exploration (Full Data Set)
Note: When developing our formal model we first split the data set into a training and test set.  However, we also performed some exploratory analysis on the full data set. Given that a model using the full data set can not be validated using ROC/AUC, this is purely for exploratory purposes. This exploratory analysis is summarized below.

### Model Selection Exploration - Full Data Set
Define full and null models - used in Forward Selection, Backward Elimination, and Stepwise Regression
```{r}
fullmod <- glm(dead_num ~. , data = nass, family = "binomial" ,maxit = 100)
Nullmod <- glm(dead_num~1, data = nass, family = "binomial")
```

All Regression
```{r}
##perform all possible regressions (1st order)
allreg <- regsubsets(dead_num ~., data=nass, nbest=5)

##create a "data frame" that stores the predictors in the various models considered as well as their various criteria
best <- as.data.frame(summary(allreg)$outmat)
best$p <- as.numeric(substr(rownames(best),1,1))+1
best$r2 <- summary(allreg)$rsq
best$adjr2 <- summary(allreg)$adjr2
best$mse <- (summary(allreg)$rss)/(dim(nass)[1]-best$p)
best$cp <- summary(allreg)$cp
best$bic <- summary(allreg)$bic
best

##Sort by:
#best[order(best$r2),]
#best[order(best$adjr2),]
best[order(best$mse),]
#best[order(best$cp),]
#best[order(best$bic),]

```


Backward Elimination
```{r}
step(fullmod, scope=list(lower=Nullmod, upper=fullmod), direction="backward")
```

Stepwise Regression
```{r}
step(Nullmod, scope=list(lower=Nullmod, upper=fullmod), direction="both")
```

Forward Selection
```{r}
# forward selection
step(Nullmod, scope=list(lower=Nullmod, upper=fullmod), direction="forward")
```

### Model Comments:
Forward Selection, Backward Elimination, and Stepwise Regression each yielded the same model. 

Choose the following variables in the model we choose based upon (i) exploratory analysis, and (ii) intuition of important factors (speed of accident, seatbelts, etc. - each seem reasonable).

- dvcat (speed)
- seatbelt
- frontal
- sex
- ageOFocc
- abcat (airbag deployment)
- occRole


Exploratory Model (full data set)
```{r}
model_picked <- glm(formula = dead_num ~ dvcat + seatbelt + frontal + sex + ageOFocc + 
    abcat + occRole, family = "binomial", data = nass, maxit = 100)

summary(model_picked)
```
Wald Test on individual predictors:

Wald test: Z = B_j - 0 / se(B_j)

Normal Distribution

Note: Can just compare z-value from summary table to qnorm(0.975)

```{r}
qnorm(0.975)
```
Can remove:

-dvcat10-24 (we chose to combine with the reference class, resulting in speed <25km/hr)
-abcatunavail (we chose to not combine with reference class given different contextual interpretations)


Generalized VIF, Delta G^2
```{r}
faraway::vif(model_picked)
car::vif(model_picked)
1-pchisq(Nullmod$deviance-model_picked$deviance, 11)
```
Note:

- VIF (faraway package) not suited to logistic regression
- GVIF^(1/2*DF) - low values indicate that multicollinearity is not present
- Delta G^2 - indicates that the model is useful (relative to the intercept only model)


# 4. Model Selection, Formalization, and Validation (Test & Train Data Set)

Split Data into Training & Test Set
```{r}
#creating training and testing dataset
set.seed(40)
sample<-sample.int(nrow(nass), floor(.50*nrow(nass)), replace = F)
train<-nass[sample, ]
test<-nass[-sample, ]
```

Automatic Search Processes (Backward Elimination, Stepwise Regression, Forward Selection)
```{r}
#Define Full Model and Null Model
fullmod.train <- glm(dead_num ~. , data = train, family = "binomial" ,maxit = 100)
Nullmod.train <- glm(dead_num~1, data = train, family = "binomial")

# Backward Elimination
step(fullmod.train, scope=list(lower=Nullmod.train, upper=fullmod.train), direction="backward")

# Stepwise Regression
step(Nullmod.train, scope=list(lower=Nullmod.train, upper=fullmod.train), direction="both")

# Forward Selection
step(Nullmod.train, scope=list(lower=Nullmod.train, upper=fullmod.train), direction="forward")

```
Note: 


- Each of the processes results in the same model
- Automatic search processes ignore interaction terms (explored in subsequent analysis)


Fit Model to training data
Obtain Critical value for Wald Test
```{r}
model_final <- glm(formula = dead_num ~ dvcat + seatbelt + frontal + sex + ageOFocc + 
    abcat + occRole, family = "binomial", data = train, maxit = 100)

summary(model_final)

#Critical value for Wald Test
qnorm(0.975) 
```
Note: Consistent with results from model based on full data set, we can combine dvcat10-24 with the reference class. In addition, it intuitively makes sense that differentiating speeds of relatively slow accidents may add little additional predictive power in identifying fatalities.


#### Combine appropriate accident speeds 
Combine dvcat 10-24 with reference class. Rename to "1-24"

```{r}

# Full Data Set - combine categories
nass$New_dvcat=nass$dvcat
levels(nass$New_dvcat)<-c(levels(nass$New_dvcat),"1-24")
nass$New_dvcat[nass$dvcat=="1-9km/h"]<-"1-24"
nass$New_dvcat[nass$dvcat=="10-24"]<-"1-24"
nass$New_dvcat <- droplevels(nass$New_dvcat)
levels(nass$New_dvcat)
nass$New_dvcat<- relevel(nass$New_dvcat, ref = "1-24")
levels(nass$New_dvcat)

# Test Data Set - combine categories
test$New_dvcat=test$dvcat
levels(test$New_dvcat)<-c(levels(test$New_dvcat),"1-24")
test$New_dvcat[test$dvcat=="1-9km/h"]<-"1-24"
test$New_dvcat[test$dvcat=="10-24"]<-"1-24"
test$New_dvcat <- droplevels(test$New_dvcat)
levels(test$New_dvcat)
test$New_dvcat<- relevel(test$New_dvcat, ref = "1-24")
levels(test$New_dvcat)


# Train Data Set - combine categories
train$New_dvcat=train$dvcat
levels(train$New_dvcat)<-c(levels(train$New_dvcat),"1-24")
train$New_dvcat[train$dvcat=="1-9km/h"]<-"1-24"
train$New_dvcat[train$dvcat=="10-24"]<-"1-24"
train$New_dvcat <- droplevels(train$New_dvcat)
levels(train$New_dvcat)
train$New_dvcat<- relevel(train$New_dvcat, ref = "1-24")
levels(train$New_dvcat)
```

#### Refit model based upon new categorization
```{r}
model_final <- glm(formula = dead_num ~ New_dvcat + seatbelt + frontal + sex + ageOFocc + 
    abcat + occRole, family = "binomial", data = train, maxit = 100)

summary(model_final)
```

#### Explore Interaction Terms

Interaction Terms - dvcat (speed) & seatbelt
```{r}

# New_dvcat & seatbelt

#model_reduced <- glm(formula = dead_num ~ New_dvcat + seatbelt, family = "binomial", data = nass, maxit = 100)
model_final.interaction1 <- glm(formula = dead_num ~ New_dvcat + seatbelt + frontal + sex + ageOFocc + 
    abcat + occRole + New_dvcat*seatbelt, family = "binomial", data = train, maxit = 100)
summary(model_final.interaction1)

# Delta G squared
1-pchisq(model_final$deviance-model_final.interaction1$deviance, 3)

```
Note:

- The Delta G^2 test indicates that the interaction terms are significant and should be included
- Observing the coefficients, all dvcat and the seatbelt coefficient are higher, while the interaction terms are negative (more likely to survive)


Interaction Terms - dvcat (speed) & abcat (airbag)
```{r}
# New_dvcat & abcat
model_final.interaction2 <- glm(formula = dead_num ~ New_dvcat + seatbelt + frontal + sex + ageOFocc + abcat + occRole + New_dvcat * seatbelt + New_dvcat*abcat, family = "binomial", data = train, maxit = 100)

summary(model_final.interaction2)

# Delta G squared
1-pchisq(model_final.interaction1$deviance-model_final.interaction2$deviance, 6)

```
Note:

- The Delta G^2 test indicates that given the existing predictors in the model, the proposed interaction terms (dvcat & abcat or speed and airbag) are not significant and can be excluded


Interaction Terms - dvcat (speed) & frontal
```{r}
# New_dvcat & abcat
model_final.interaction3 <- glm(formula = dead_num ~ New_dvcat + seatbelt + frontal + sex + ageOFocc + abcat + occRole + New_dvcat * seatbelt + New_dvcat*frontal, family = "binomial", data = train, maxit = 100)

summary(model_final.interaction3)

# Delta G squared
1-pchisq(model_final.interaction1$deviance-model_final.interaction3$deviance, 3)

```
Note:

- The Delta G^2 test indicates that given the existing predictors in the model, the proposed interaction terms (dvcat & abcat or speed and airbag) are not significant and can be excluded


Directly compare the coefficients of the two models in a single table
```{r}
export_summs(model_final, model_final.interaction1, scale = FALSE)
```
Note: the interaction terms are negative, but original categorical variables are higher. Look at net effect, including change in intercept


Net Effect  55+
```{r}
#Looking only at: seatbelt = none, a particular speed, change in intercept
##Note: assume everything else belongs to reference classes; also coefficient for age of occupant is unchanged

#55+: w/ interaction terms
model_final.interaction1$coefficients["seatbeltnone"]
model_final.interaction1$coefficients["New_dvcat55+"]
model_final.interaction1$coefficients["New_dvcat55+:seatbeltnone"]
model_final.interaction1$coefficients["(Intercept)"]

Total_Int <- model_final.interaction1$coefficients["New_dvcat55+"] + model_final.interaction1$coefficients["seatbeltnone"]+ model_final.interaction1$coefficients["New_dvcat55+:seatbeltnone"] + model_final.interaction1$coefficients["(Intercept)"]

#55+: w/o interaction terms
model_final$coefficients["seatbeltnone"]
model_final$coefficients["New_dvcat55+"]
model_final$coefficients["(Intercept)"]

Total <- model_final$coefficients["New_dvcat55+"] + model_final$coefficients["seatbeltnone"]+ model_final$coefficients["(Intercept)"]

print("Model w/ Interacions")
Total_Int

print("Model w/o Interacions")
Total

```

Net Effect  25-39
```{r}
#Looking only at: seatbelt = none, a particular speed, change in intercept
##Note: assume everything else belongs to reference classes; also coefficient for age of occupant is unchanged

#25-39: w/ interaction terms
model_final.interaction1$coefficients["seatbeltnone"]
model_final.interaction1$coefficients["New_dvcat25-39"]
model_final.interaction1$coefficients["New_dvcat25-39:seatbeltnone"]
model_final.interaction1$coefficients["(Intercept)"]

Total_Int25 <- model_final.interaction1$coefficients["New_dvcat25-39"] + model_final.interaction1$coefficients["seatbeltnone"]+ model_final.interaction1$coefficients["New_dvcat25-39:seatbeltnone"] + model_final.interaction1$coefficients["(Intercept)"]

#25-39:: w/o interaction terms
model_final$coefficients["seatbeltnone"]
model_final$coefficients["New_dvcat25-39"]
model_final$coefficients["(Intercept)"]

Total25 <- model_final$coefficients["New_dvcat25-39"] + model_final$coefficients["seatbeltnone"]+ model_final$coefficients["(Intercept)"]

print("Model w/ Interacions")
Total_Int25

print("Model w/o Interacions")
Total25

```
Note: The overall effect of the interaction terms signifies that while seatbelts are always beneficial (save lives / lower probability of death), they are more beneficial at lower speeds. 


#### Outliers and Influential Data Points

```{r}
# Influential Points Check
n<-nrow(train)
p<-15

# Cook's Distance
print("cooks")
COOKS<-cooks.distance(model_final.interaction1)
COOKS[COOKS>qf(0.5,p,n-p)]

# DFFITS
print("DFFITS")
DFFITS<-dffits(model_final.interaction1)
DFFITS[abs(DFFITS)>2*sqrt(p/n)]

# DFBETAS
print('DFBETAS')
DFBETAS<-dfbetas(model_final.interaction1)
DFBETAS[abs(DFBETAS)>2/sqrt(n)]

# Plotting
par(mfrow=c(1,2))

dffits.ep <- dffits(model_final.interaction1)
plot(seq(1, length(dffits.ep), 1),dffits.ep,type="l", main="DFFITS Plot",
       xlab="Index", ylab="Dffits")
abline(h=2*sqrt(p/n), col="red")
abline(h=-2*sqrt(p/n), col="red")

dfbetas.ep <- dfbetas(model_final.interaction1)
plot(seq(1, length(dfbetas.ep), 1),dfbetas.ep,type="l", main="DFBETAS Plot",
       xlab="Index", ylab="DFBETAS")
abline(h=2*sqrt(p/n), col="red")
abline(h=-2*sqrt(p/n), col="red")

cook.ep <- cooks.distance(model_final.interaction1)
plot(seq(1, length(cook.ep), 1),cook.ep,type="l", main="Cook's Distance",
       xlab="Index", ylab="Cook's Distance", ylim=c(0,1))
abline(h=qf(0.5,p,n-p), col="red")
```
Note: DFFITS, DFBETAS, and Cook's Distance yield significantly different results.

Number of influential data points (as proportion of training data):
```{r}
#Cooks
print("Cook's Distance:")
length(COOKS[COOKS>qf(0.5,p,n-p)])/nrow(train)

#DFFITS
print("DFFITS:")
length(DFFITS[abs(DFFITS)>2*sqrt(p/n)])/nrow(train)

#DFBETAS
print("DFBETAS:")
length(DFBETAS[abs(DFBETAS)>2/sqrt(n)])/nrow(train)

```
Note:

- Cook's Distance - 0%
- DFFITS - 9.7%
- DFBETAS - 75.1%

We expect that the significant differences arose from the fact that we were fitting a logistic regression model with numerous categorical variables using a fairly unbalanced set of observations. 

Additional emphasis was placed on our exploratory data analysis (referenced above) to identify potential influential observations.


#### Confusion Matrices

##### Confusion Matrices - Original Model (no interaction terms - for comparison)
Explore Confusion Matrices for various values of lambda
Model without interaction terms (for comparison)
```{r}
preds.noI<-predict(model_final,newdata=test, type="response")

## Confusion Matrices - Original Model (for comparison)
table(test$dead_num, preds.noI>0.01)
table(test$dead_num, preds.noI>0.05)
table(test$dead_num, preds.noI>0.1)
table(test$dead_num, preds.noI>0.25)
table(test$dead_num, preds.noI>0.5)
```

##### Confusion Matrices (final model with interaction terms)
Explore Confusion Matrices for various values of lambda
```{r}
preds<-predict(model_final.interaction1,newdata=test, type="response")

## Confusion Matrices
table(test$dead_num, preds>0.01)
table(test$dead_num, preds>0.05)
table(test$dead_num, preds>0.1)
table(test$dead_num, preds>0.25)
table(test$dead_num, preds>0.5)
```

Given use cases (first responders, insurance companies), are more concerned with correctly identifying deaths even at the cost of higher false positive rates, select lower value of lambda. However, we would like to select a cutoff value that balances false positives with sensitivity.

##### Optimal Lambda Calculation (sensitivity vs. specification)
```{r}
library(Epi)
rc <- ROC(form = dead_num ~ New_dvcat + seatbelt + frontal + sex + 
    ageOFocc + abcat + occRole + New_dvcat * seatbelt, data = test, plot=c("sp", "ROC") )
## optimal combination
opt <- which.max(rowSums(rc$res[, c("sens", "spec")]))
## optimal cut-off point 
rc$res$lr.eta[opt]
```
Note: while the optimal value calculated for the current sample is 0.061, after taking numerous samples an optima value of 0.05 seems more typical (see subsequent code).

##### Confusion Matrices - Detailed
After identifying lamda = .05 as roughly the cutoff that struck the optimal balance, we drilled in with greater detail:
```{r}
table(test$dead_num, preds>0.03)
table(test$dead_num, preds>0.04)
table(test$dead_num, preds>0.05)
table(test$dead_num, preds>0.06)
table(test$dead_num, preds>0.07)
```
After evaluating in greater detail, we decided to use lambda = 0.05 as our cutoff.



### Model Validation

#### Model Accuracy Details
False Positive Rate (Type I Error Rate)
False Negative Rate (Type II Error Rate)
Overall Error Rate
Sensitivity
Specificity

```{r}
#Refers to model with interaction terms

lam <- 0.05 #Selected value of lambda

#Confusion Matrix
t <- table(test$dead_num, preds>lam)
t

#Identify True Negatives, True Positives, False Negatives, False Positives
n <- nrow(test) #Number observations
TN <- t[1,1] #True Negatives
FP <- t[1,2] #False Positives
FN <- t[2,1] #False Negatives
TP <- t[2,2] #True Positives

#False Positive Rate (Type I Error Rate)
FPR <- FP / (TN+FP)
FPR

#False Negative Rate (Type II Error Rate)
FNR <- FN / (FN + TP)
FNR

#Overall Error Rate
OER <- (FP+FN) / n
OER

#Sensitivity: P(y_hat = 1 | y = 1)
sensitivity <- TP / (FN + TP)
sensitivity

#Specificity: P:(y_hat = 0 | y = 0)
specificity <- TN / (TN + FP)
specificity
```


#### ROC Curve
```{r}
#ROC
rates<-prediction(preds, test$dead_num)
roc_result<-performance(rates,measure="tpr", x.measure="fpr")

plot(roc_result, main="Model ROC Curve")
lines(x = c(0,1), y = c(0,1), col="red")
lines(x = c(FPR, FPR), y= c(-1,2), col="blue")
```

#### AUC
```{r}
##compute the AUC
aucvalues <- performance(rates, measure = "auc")
auc <- aucvalues@y.values[[1]]
auc
```
#### GVIF, Delta G^2

Generalized VIF - detect multicollinearity 

Delta G^2 - indicates if model is useful (relative to Null model)
```{r}
faraway::vif(model_final.interaction1)
car::vif(model_final.interaction1)
1-pchisq(Nullmod.train$deviance-model_final.interaction1$deviance, 13)

#Model without interaction terms - for reference
faraway::vif(model_final)
car::vif(model_final)
1-pchisq(Nullmod.train$deviance-model_final$deviance, 10)
```
GVIF^(1/2*DF) - low values for model without interaction terms indicate that multicollinearity is not present. Once interaction terms are introduced, some multicollinearity may be present, regarding seatbelt, dvcat, and the interaction term (as expected)

Delta G^2 - indicates that the model is useful (relative to the intercept only model)

#### K- Fold Cross Validation
10 Fold Cross Validation for lambda = 0.05
```{r}
# Cross Validation with changeable threshold. 

model_picked.interaction1 <- glm(formula = dead_num ~ New_dvcat + seatbelt + frontal + sex + ageOFocc + 
    abcat + occRole + New_dvcat*seatbelt, family = "binomial", data = nass, maxit = 100)

mycost <- function(r, pi){
     weight1 = 1 #cost for getting 1 wrong
     weight0 = 1 #cost for getting 0 wrong
     c1 = (r==1)&(pi<0.05) #logical vector - true if actual 1 but predict 0
     c0 = (r==0)&(pi>=0.05) #logical vector - true if actual 0 but predict 1
     return(mean(weight1*c1+weight0*c0))
 }
a <- cv.10 <- cv.glm(nass, model_picked.interaction1,cost = mycost, K=10)

a$delta[1] #Overall Error Rate
1-a$delta[1] #Accuracy
```
Note: Overall Error Rate is consistent with that observed in our model (0.1889686)


#### Iterating Test/Train Split

```{r}
#Running for loop of train test split

#run the train test split 10 times and make 10 different confusion matrices 
#this is to ensure the train test split does not influence the confusion matrices that much
for(i in 1:10) {
  #make train and test
  sample<-sample.int(nrow(nass), floor(.50*nrow(nass)), replace = F)
  train<-nass[sample, ]
  test<-nass[-sample, ]
  
  
  #selected final model
  model_rep.interaction1 <- glm(formula = dead_num ~ New_dvcat + seatbelt + frontal + sex + ageOFocc + 
                                    abcat + occRole + New_dvcat*seatbelt, family = "binomial", data = train, maxit = 100)
  
  
  preds<-predict(model_rep.interaction1,newdata=test, type="response")
  
  print(table(test$dead_num, preds>0.05))}
#Number of false positives ranges from 104 to 128,
# the variability is not that great in confusion matrices based on random test splits

```



#### Test Refit of Data
Check for consistency in sampling

- Resample
- Calculate key statistics (AUC, Optimal Cutoff, Residual Deviance, Intercept - as an arbitrary coefficient)
- Repeat multiple times


```{r}
tbl <- data.frame(c(0,0,0,0))

for (i in 1:20) {
  
  #creating training and testing dataset
  #No set seed used
  Rsample<-sample.int(nrow(nass), floor(.50*nrow(nass)), replace = F)
  Rtrain<-nass[Rsample, ]
  Rtest<-nass[-Rsample, ]
  
  #Fit Model
  model_final.R <- glm(formula = dead_num ~ New_dvcat + seatbelt + frontal + sex + ageOFocc + 
      abcat + occRole + New_dvcat*seatbelt, family = "binomial", data = Rtrain, maxit = 100)
  
  ## Confusion Matrices - Original Model (for comparison)
  Rpreds<-predict(model_final.R,newdata=Rtest, type="response")
  table(Rtest$dead_num, Rpreds>0.05)
  
  #ROC
  Rrates<-prediction(Rpreds, Rtest$dead_num)
  Rroc_result<-performance(Rrates,measure="tpr", x.measure="fpr")
  
  #compute the AUC
  Raucvalues <- performance(Rrates, measure = "auc")
  Rauc <- Raucvalues@y.values[[1]]
  
  #Compute Optimal Lambda
  Rrc <- ROC(form = dead_num ~ New_dvcat + seatbelt + frontal + sex + 
      ageOFocc + abcat + occRole + New_dvcat * seatbelt, data = Rtest)
  
  # optimal combination
  Ropt <- which.max(rowSums(Rrc$res[, c("sens", "spec")]))
  
  
  ### Output:
  summary(model_final.R)
  
  # optimal cut-off point
  Rrc$res$lr.eta[Ropt]
  # AUC
  Rauc
  # Residual Deviance
  model_final.R$deviance
  
  t <- c(Rauc, Rrc$res$lr.eta[Ropt], model_final.R$deviance, model_final.R$coefficients["(Intercept)"])
  tbl[i] = t 
}

tbl
```
Note: In general, we observe consistency in a number of key metrics (AUC, optimal lambd calculation, deviance, and coefficients). Additionally the sample we chose to fit the model is not show significantly different results from others generally observed.


# 5. Highlighting Unique Observations
Additional Information and Facts/Highlights used in write-up

#### Survival/Death Counts
```{r}
#Number of Deaths and Accident Survivors
lengths(nass)
sum(nass$dead_num == 0)
sum(nass$dead_num == 1)
```

#### Comparison of individual variables

```{r}
# dvcat (speed) vs. seatbelt 

#dvcat (speed)
model_dvcat <- glm(formula = dead_num ~ New_dvcat, family = "binomial", data = train, maxit = 100)
summary(model_dvcat)

#seatbelt
model_seatbelt <- glm(formula = dead_num ~ seatbelt, family = "binomial", data = train, maxit = 100)
summary(model_seatbelt)

#frontal
model_frontal <- glm(formula = dead_num ~ frontal, family = "binomial", data = train, maxit = 100)
summary(model_frontal)

#abcat (airbags)
model_abcat <- glm(formula = dead_num ~ abcat, family = "binomial", data = train, maxit = 100)
summary(model_abcat)

#ageOfocc
model_age <- glm(formula = dead_num ~ ageOFocc, family = "binomial", data = train, maxit = 100)
summary(model_age)
model_NULL <- glm(formula = dead_num ~ 1, family = "binomial", data = train, maxit = 100)

model_dvcat$deviance
model_seatbelt$deviance
model_frontal$deviance
model_abcat$deviance
model_age$deviance

```



```{r}
#Define new data set
nassAge <- nass[nass$ageOFocc<80, ]

#Fit
model_80 <- glm(formula = dead_num ~ New_dvcat + seatbelt + frontal + sex + ageOFocc + 
      abcat + occRole + New_dvcat*seatbelt, family = "binomial", data = nassAge, maxit = 100)

#Compare to model fit to full data set
summary(model_80)
summary(model_picked.interaction1)
```


