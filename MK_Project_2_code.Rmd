---
title: "Untitled"
author: "Michael Kastanowski"
date: "10/30/2020"
output: html_document
---

```{r}
library(dplyr)
library(ggplot2)
library(MASS)
library(ROCR) #ROC Curve
library(nnet)
library(leaps)
library(faraway)
library(car)
library(glmnet)
library(boot)

library(caret) 
library(ISLR)
library(tidyverse) 
```


```{r}
setwd("~/Desktop/STAT Project")
nass<-read.csv("nassCDS.csv",header=TRUE)

attach(nass)
#which(is.na(nass), arr.ind=TRUE)

nass
```

```{r}
#convert categorical to factor
nass$dead<-factor(nass$dead) 
nass$dvcat<-factor(nass$dvcat)
nass$airbag<-factor(nass$airbag)
nass$abcat<-factor(nass$abcat)
nass$seatbelt<-factor(nass$seatbelt)
nass$sex<-factor(nass$sex)
nass$abcat<-factor(nass$abcat)
nass$occRole<-factor(nass$occRole)


#reset reference class
nass$seatbelt<-relevel(nass$seatbelt, ref = "none")
nass$airbag<-relevel(nass$airbag, ref ="none")
```

```{r}
#'convert' dead to numeric
dead_num<-nass$dead
levels(dead_num)<-c(0,1)
nass$dead_num <- dead_num

```
```{r}
#model selection
set.seed(139)
sample<-sample.int(nrow(nass), floor(.50*nrow(nass)), replace = F)
train<-nass[sample, ]
test<-nass[-sample, ]

#null model
#regnull <- glm(dead_num~1, data=train, family = "binomial")
##model with all predictors
#regfull <- glm(dead_num~., data=train, family = "binomial")

#step(regfull, scope=list(lower=Nullmod, upper=fullmod), direction="backward")
#step(regfull scope=list(lower=Nullmod, upper=fullmod), direction="both")
```


```{r}
#multinomial regression

#result<-glm(dead_num~dvcat+ageOFocc+yearVeh+frontal+injSeverity+as.numeric(weight)+seatbelt+airbag+deploy+occRole+sex, data = nass, family ="binomial")

model_expl <- glm(dead_num~dvcat+abcat+seatbelt+frontal+ageOFocc+occRole+yearVeh, data = nass, family = "binomial")

model_null <- glm(dead_num~1, "binomial")
```
```{r}
#G Test and Walds Test
model_mult <- multinom(dead_num~dvcat+abcat+frontal+ageOFocc+occRole+yearVeh)


#Delta G test
1-pchisq(model_null$deviance-model_expl$deviance, 7)

#Wald Statistics 

z<-summary(model_mult)$coefficients/summary(model_mult)$standard.errors
z

##compute corresponding p-values
p<-(1 - pnorm(abs(z)))*2
p
```
Deploy is above .05, drop Deploy from model.

```{r}
#new exploratory Model
model_expl <- glm(dead_num~dvcat+abcat+frontal+ageOFocc+occRole+yearVeh, data = nass, family = "binomial")
summary(model_expl)
```

```{r}
#validation
set.seed(139)
sample<-sample.int(nrow(nass), floor(.50*nrow(nass)), replace = F)
train<-nass[sample, ]
test<-nass[-sample, ]
preds<-predict(model_expl,newdata=test, type="response")
preds[is.na(preds)]<-0
rates<-prediction(preds, test$dead_num)
roc_result<-performance(rates,measure="tpr", x.measure="fpr")
plot(roc_result, main="ROC Curve for nass")
lines(x = c(0,1), y = c(0,1), col="red")

aucvalues <- performance(rates, measure = "auc")
auc <- aucvalues@y.values[[1]]
auc


```

AUC is 0.8685021, model is highly predictive
```{r}
#Confusion Matrices
table(test$dead_num, preds>0.1)
#table(test$dead_num, preds>0.25)
table(test$dead_num, preds>0.5)
#table(test$dead_num, preds>0.75)
```
For Threshold of 0.1

False Positive Rate: 1188/12478 = 0.09520757

True Positive Rate: 409/631 = 0.6481775

Overall Error Rate: (222+1188)/12478 =0.1129989



For Threshold of 0.5

False Positive rate: 42/12478 = 0.003365924

True Positive Rate: 59/631 =0.09350238

Overall Error Rate: (572+42)/12478 = 0.0492066



All p values less than .05 except for deploy(drop deploy)


```{r}
vif(model_expl)

```


```{r}
#LOOCV on sample of the model
set.seed(139)
sub_sample_1<-sample.int(nrow(nass), floor(.05*nrow(nass)), replace = F)

loocv_sample<-nass[sub_sample_1, ]
model_picked <- glm(formula = dead_num ~ dvcat + seatbelt + frontal + sex + ageOFocc + 
    abcat + occRole, family = "binomial", data = loocv_sample, maxit = 100)

#cv.err<-cv.glm(loocv_sample, model_picked)
#cv.err$delta[1] ##the output for the LOOCV should match your own
#cv.glm(loocv_sample, model_picked, K=5)$delta[1] ##k fold CV with k=10

```

```{r}
# K-Fold Cross Validation on full model
train_control <- trainControl(method = "cv", 
                              number = 10)
train_control_r <- trainControl(method = "repeatedcv", 
                              number = 10, repeats = 3)
#k-fold
k_model <- train(dead_num ~ dvcat + seatbelt + frontal + sex + ageOFocc + 
    abcat + occRole, data = nass,  
               method = "glm", 
               trControl = train_control) 
print(k_model)


1-k_model$results$Accuracy
```



```{r}
#repeated_k fold
kRep_model <- train(dead_num ~ dvcat + seatbelt + frontal + sex + ageOFocc + 
    abcat + occRole, data = nass,  
               method = "glm", 
               trControl = train_control_r) 

kRep_model
1-kRep_model$results$Accuracy
```

```{r}
#K Fold via another means
glm.fit<-glm(dead_num ~ dvcat + seatbelt + frontal + sex + ageOFocc + abcat + occRole, data=nass, family = "binomial")
#cv.err<-cv.glm(test, glm.fit)
#cv.err$delta[1] ##the output for the LOOCV should match your own
cv.glm(nass, glm.fit, K=10)$delta[1] ##k fold CV with k=10
```

```{r}
#best lambda calculation
x<-model.matrix(dead_num~dvcat + seatbelt + frontal + sex + ageOFocc + 
    abcat + occRole, nass)[,-1]
y<-nass$dead_num

train_lam<-sample(1:nrow(x), nrow(x)/2) 
test_lam<-(-train_lam)
y.tes_lamt<-y[test_lam] 
cv.out<-cv.glmnet(x[train_lam,],y[train_lam],alpha=1, family ="binomial") 
bestlam<-cv.out$lambda.min
bestlam
```

